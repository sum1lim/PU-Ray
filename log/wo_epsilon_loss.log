Number of training queries: 983040
Epoch 0, Loss: 0.28092566496238564 / MAE: 0.10709144973386751 / RMSE: 0.1550177379552601
Validation Loss: 0.17990340009620492 / MAE: 0.05821189029462124 / RMSE: 0.07925910462479173
Save model to ./models/wo_epsilon.pt
Epoch 1, Loss: 0.16170604523719448 / MAE: 0.049820359925292726 / RMSE: 0.06931928662381046
Validation Loss: 0.1445613433495693 / MAE: 0.042386867814082435 / RMSE: 0.0601006126739208
Save model to ./models/wo_epsilon.pt
Epoch 2, Loss: 0.13916382074473133 / MAE: 0.04111688501822069 / RMSE: 0.05837178416195983
Validation Loss: 0.1343218975710731 / MAE: 0.03957414546241554 / RMSE: 0.0566200325537502
Save model to ./models/wo_epsilon.pt
Epoch 3, Loss: 0.1315598653181464 / MAE: 0.038963813367764895 / RMSE: 0.05571109096149431
Validation Loss: 0.1302308817068575 / MAE: 0.03894046260090339 / RMSE: 0.055315344978904814
Save model to ./models/wo_epsilon.pt
Epoch 4, Loss: 0.12584221412895824 / MAE: 0.03746412014271939 / RMSE: 0.05350560933511204
Validation Loss: 0.12257006374543161 / MAE: 0.036471904630753664 / RMSE: 0.05193376531939891
Save model to ./models/wo_epsilon.pt
Epoch 5, Loss: 0.12260185031075964 / MAE: 0.036852551358712196 / RMSE: 0.05227942078288906
Validation Loss: 0.11796579820361545 / MAE: 0.03508058949337398 / RMSE: 0.05021513260790327
Save model to ./models/wo_epsilon.pt
Epoch 6, Loss: 0.11688698135505264 / MAE: 0.034973538410892756 / RMSE: 0.049775818547683266
Validation Loss: 0.11443180675189737 / MAE: 0.034208562520004385 / RMSE: 0.048882586680579786
Save model to ./models/wo_epsilon.pt
Epoch 7, Loss: 0.11499429183606118 / MAE: 0.03465047152724961 / RMSE: 0.049145121160544675
Validation Loss: 0.11154299435170476 / MAE: 0.033369455457249675 / RMSE: 0.04746042154719809
Save model to ./models/wo_epsilon.pt
Epoch 8, Loss: 0.11151109402366241 / MAE: 0.03358611809771572 / RMSE: 0.04760193457757855
Validation Loss: 0.1092574520696287 / MAE: 0.03285317899282868 / RMSE: 0.0466392385594587
Save model to ./models/wo_epsilon.pt
Epoch 9, Loss: 0.10939759443966945 / MAE: 0.03311021090531705 / RMSE: 0.04686841450842585
Validation Loss: 0.10700233062792996 / MAE: 0.03225227962560555 / RMSE: 0.04576254053392528
Save model to ./models/wo_epsilon.pt
Epoch 10, Loss: 0.10777702499209049 / MAE: 0.032806191025241765 / RMSE: 0.04642283610224622
Validation Loss: 0.10493983076847425 / MAE: 0.03180311622328288 / RMSE: 0.04515722865420288
Save model to ./models/wo_epsilon.pt
Epoch 11, Loss: 0.10632500083044805 / MAE: 0.03260150706868853 / RMSE: 0.046014908428297294
Validation Loss: 0.11946738026265735 / MAE: 0.036904358542361175 / RMSE: 0.050375472259257266
Epoch 12, Loss: 0.10605653968656584 / MAE: 0.03210842101116133 / RMSE: 0.0453352427260282
Validation Loss: 0.10263859043851051 / MAE: 0.0315006540330625 / RMSE: 0.04445794597499303
Save model to ./models/wo_epsilon.pt
Epoch 13, Loss: 0.1015077957215907 / MAE: 0.03114016607152766 / RMSE: 0.04401133740492287
Validation Loss: 0.09912921578263643 / MAE: 0.03034291437612923 / RMSE: 0.04310398376425893
Save model to ./models/wo_epsilon.pt
Epoch 14, Loss: 0.10037342329269841 / MAE: 0.031059811066822596 / RMSE: 0.04380165594516946
Validation Loss: 0.09802799178432399 / MAE: 0.030162100856598484 / RMSE: 0.04291080315051097
Save model to ./models/wo_epsilon.pt
Epoch 15, Loss: 0.09777139876624803 / MAE: 0.030289353990625406 / RMSE: 0.04282352000902511
Validation Loss: 0.09615635471632535 / MAE: 0.02963824916649663 / RMSE: 0.04225476343335751
Save model to ./models/wo_epsilon.pt
Epoch 16, Loss: 0.12977087682889119 / MAE: 0.04165624970765603 / RMSE: 0.0589011535954426
Validation Loss: 0.1136227474011772 / MAE: 0.0332341063701914 / RMSE: 0.04741161711392226
Epoch 17, Loss: 0.10722195832350433 / MAE: 0.03133452986693497 / RMSE: 0.04461030206385448
Validation Loss: 0.10366701253230427 / MAE: 0.03055954869345451 / RMSE: 0.043525636289047556
Epoch 18, Loss: 0.10153591815256392 / MAE: 0.030360145183515014 / RMSE: 0.04308747917365581
Validation Loss: 0.09935402587639407 / MAE: 0.02981689744970882 / RMSE: 0.04240879083810731
Epoch 19, Loss: 0.09964246400048386 / MAE: 0.030264072348612617 / RMSE: 0.04287615901664377
Validation Loss: 0.09829879232000582 / MAE: 0.029838153727529623 / RMSE: 0.04234116860865612
Epoch 20, Loss: 0.09652704342331676 / MAE: 0.029270807216156245 / RMSE: 0.041604129024766234
Validation Loss: 0.09597419722228066 / MAE: 0.029057764805893647 / RMSE: 0.04146541068382251
Save model to ./models/wo_epsilon.pt
Epoch 21, Loss: 0.09664050989493507 / MAE: 0.029590167930348348 / RMSE: 0.04193688812120963
Validation Loss: 0.09508495416387758 / MAE: 0.028923766858634042 / RMSE: 0.04124336744665276
Save model to ./models/wo_epsilon.pt
Epoch 22, Loss: 0.09443273997994871 / MAE: 0.028833406502648446 / RMSE: 0.04098625508883965
Validation Loss: 0.09361973231075292 / MAE: 0.02847112686280562 / RMSE: 0.04072334754517225
Save model to ./models/wo_epsilon.pt
Epoch 23, Loss: 0.09361758633225144 / MAE: 0.028647295128732233 / RMSE: 0.040731178954116425
Validation Loss: 0.0927742037748658 / MAE: 0.028283514796317095 / RMSE: 0.0403944422452983
Save model to ./models/wo_epsilon.pt
Epoch 24, Loss: 0.09266155163796849 / MAE: 0.028380121753542972 / RMSE: 0.0403828313443846
Validation Loss: 0.0921570673943838 / MAE: 0.02805010312930419 / RMSE: 0.04025704983963805
Save model to ./models/wo_epsilon.pt
Epoch 25, Loss: 0.09173421025759323 / MAE: 0.028106169915988907 / RMSE: 0.04004664989418996
Validation Loss: 0.09121714698437353 / MAE: 0.02787425349700169 / RMSE: 0.039919442517301826
Save model to ./models/wo_epsilon.pt
Epoch 26, Loss: 0.09205210136746758 / MAE: 0.02836095644369516 / RMSE: 0.04033665783251199
Validation Loss: 0.09040061957046124 / MAE: 0.02762278718945998 / RMSE: 0.03961100547962523
Save model to ./models/wo_epsilon.pt
Epoch 27, Loss: 0.09045243767078517 / MAE: 0.02778353398429197 / RMSE: 0.03966233674163535
Validation Loss: 0.08988078876545011 / MAE: 0.02742734228574919 / RMSE: 0.039454313321442384
Save model to ./models/wo_epsilon.pt
Epoch 28, Loss: 0.0897868790578705 / MAE: 0.027601627837597537 / RMSE: 0.039437430420101394
Validation Loss: 0.08929723155220524 / MAE: 0.027383362908613092 / RMSE: 0.039280998273450204
Save model to ./models/wo_epsilon.pt
Epoch 29, Loss: 0.08936325975392966 / MAE: 0.027545780024430325 / RMSE: 0.03934690978575374
Validation Loss: 0.09157357414361383 / MAE: 0.028638312603073833 / RMSE: 0.04051544142561829
Epoch 30, Loss: 0.08931786485198903 / MAE: 0.02751399699220023 / RMSE: 0.03929470668813997
Validation Loss: 0.091923900456914 / MAE: 0.028452682556823206 / RMSE: 0.04034456573087503
Epoch 31, Loss: 0.08832838602839897 / MAE: 0.02718450044022369 / RMSE: 0.03889038630745387
Validation Loss: 0.08808119957377264 / MAE: 0.02707161307338757 / RMSE: 0.03889242306165195
Save model to ./models/wo_epsilon.pt
Epoch 32, Loss: 0.08758098460275371 / MAE: 0.026999039695596312 / RMSE: 0.03867732103262939
Validation Loss: 0.0873932537878092 / MAE: 0.026878546931578023 / RMSE: 0.0387027207076726
Save model to ./models/wo_epsilon.pt
Epoch 33, Loss: 0.08715699929916687 / MAE: 0.026865267439188184 / RMSE: 0.038562336602780085
Validation Loss: 0.08858334724389222 / MAE: 0.027448413093747053 / RMSE: 0.0396760880330456
Epoch 34, Loss: 0.08696162251964291 / MAE: 0.02693132859847505 / RMSE: 0.03861174488919602
Validation Loss: 0.08735963512796761 / MAE: 0.026923203534748523 / RMSE: 0.03912535218107415
Epoch 35, Loss: 0.08592805337655393 / MAE: 0.02653035198163104 / RMSE: 0.038119859969691264
Validation Loss: 0.08538198469991427 / MAE: 0.026223220067839476 / RMSE: 0.03800189959258571
Save model to ./models/wo_epsilon.pt
Epoch 36, Loss: 0.08569933382172351 / MAE: 0.02646235835469549 / RMSE: 0.038083154284012134
Validation Loss: 0.08787389871157077 / MAE: 0.02748247251842991 / RMSE: 0.039525253008694625
Epoch 37, Loss: 0.08543334612113009 / MAE: 0.026461206197309316 / RMSE: 0.03807204677019606
Validation Loss: 0.08497281530540388 / MAE: 0.026166510179644956 / RMSE: 0.037904771939478964
Save model to ./models/wo_epsilon.pt
Epoch 38, Loss: 0.08478992759577764 / MAE: 0.026234577114672215 / RMSE: 0.037753590079345825
Validation Loss: 0.08529324159485044 / MAE: 0.026233578418432293 / RMSE: 0.03799934815786189
Epoch 39, Loss: 0.08473408745780277 / MAE: 0.02619992771942035 / RMSE: 0.037761060586995604
Validation Loss: 0.08499073161133822 / MAE: 0.026167213359419565 / RMSE: 0.03792515159118505
Epoch 40, Loss: 0.08376526174988802 / MAE: 0.02587800232392291 / RMSE: 0.03741348554066037
Validation Loss: 0.08339612842720114 / MAE: 0.025712400073691116 / RMSE: 0.03747666095206
Save model to ./models/wo_epsilon.pt
Epoch 41, Loss: 0.08409575755328265 / MAE: 0.02610251272170026 / RMSE: 0.037645900275421404
Validation Loss: 0.08461280054815964 / MAE: 0.02627249433271368 / RMSE: 0.03797178587083552
Epoch 42, Loss: 0.08321212036537444 / MAE: 0.025702152301856032 / RMSE: 0.03718516634379287
Validation Loss: 0.08410322323296686 / MAE: 0.026148073897455604 / RMSE: 0.0377212805250505
Epoch 43, Loss: 0.08256498763305545 / MAE: 0.025549578543066415 / RMSE: 0.03704331503793141
Validation Loss: 0.08657406873221399 / MAE: 0.026841038825104496 / RMSE: 0.03949067424820353
Epoch 44, Loss: 0.08317365397533648 / MAE: 0.025802516739816397 / RMSE: 0.0373160539507533
Validation Loss: 0.08353586620127187 / MAE: 0.025773821728216312 / RMSE: 0.037648923042694335
Epoch 45, Loss: 0.08563114035432451 / MAE: 0.026326582204054483 / RMSE: 0.03796415754307045
Validation Loss: 0.08310046156731977 / MAE: 0.025647893310441105 / RMSE: 0.03730199501529454
Save model to ./models/wo_epsilon.pt
Epoch 46, Loss: 0.08258992065258994 / MAE: 0.025563677083970875 / RMSE: 0.03701422202275963
Validation Loss: 0.08251386395084932 / MAE: 0.025447163161740335 / RMSE: 0.0370707802541964
Save model to ./models/wo_epsilon.pt
Epoch 47, Loss: 0.08242457076607408 / MAE: 0.02555535807398065 / RMSE: 0.037014173182660225
Validation Loss: 0.08218840459260301 / MAE: 0.02526682051622868 / RMSE: 0.03702829617802956
Save model to ./models/wo_epsilon.pt
Epoch 48, Loss: 0.08170783353786867 / MAE: 0.025234219146100446 / RMSE: 0.03662173443208826
Validation Loss: 0.08217218590656061 / MAE: 0.025234447938377712 / RMSE: 0.03687205610922647
Save model to ./models/wo_epsilon.pt
Epoch 49, Loss: 0.08140139795484155 / MAE: 0.025191352520461903 / RMSE: 0.03660095864186656
Validation Loss: 0.08147266843054367 / MAE: 0.025194653384167504 / RMSE: 0.036794917999404236
Save model to ./models/wo_epsilon.pt
Epoch 50, Loss: 0.08106172715580558 / MAE: 0.025067380894878543 / RMSE: 0.036461376232938665
Validation Loss: 0.08138091461027486 / MAE: 0.025025949563223533 / RMSE: 0.03677639053200117
Save model to ./models/wo_epsilon.pt
Epoch 51, Loss: 0.08116679689151522 / MAE: 0.025178634485910147 / RMSE: 0.036570157723964186
Validation Loss: 0.08067668925672324 / MAE: 0.024962706619166504 / RMSE: 0.03653525605303944
Save model to ./models/wo_epsilon.pt
Epoch 52, Loss: 0.08097283563182597 / MAE: 0.025137431442101173 / RMSE: 0.03651996334131991
Validation Loss: 0.0813547387717352 / MAE: 0.02509982101205028 / RMSE: 0.03693387731805259
Epoch 53, Loss: 0.08052816312283854 / MAE: 0.024947277708746704 / RMSE: 0.0363439692930544
Validation Loss: 0.0810497531274164 / MAE: 0.02510931365860607 / RMSE: 0.03667228431396595
Epoch 54, Loss: 0.08090667003664301 / MAE: 0.025113840098841274 / RMSE: 0.03648331821961717
Validation Loss: 0.08056599499767736 / MAE: 0.024969740922214715 / RMSE: 0.0364731406437774
Epoch 55, Loss: 0.07970851481534123 / MAE: 0.02463090527302498 / RMSE: 0.035935704293046496
Validation Loss: 0.07990088141539163 / MAE: 0.02459688510496729 / RMSE: 0.03613604177229529
Save model to ./models/wo_epsilon.pt
Epoch 56, Loss: 0.0801193027541326 / MAE: 0.02480656787998868 / RMSE: 0.03617058728778957
Validation Loss: 0.08042348789096508 / MAE: 0.024884234944501652 / RMSE: 0.036491379982798236
Epoch 57, Loss: 0.07977481712584598 / MAE: 0.02461501679090055 / RMSE: 0.0359125753511857
Validation Loss: 0.07978737418979602 / MAE: 0.024555925728056635 / RMSE: 0.036241104615164194
Save model to ./models/wo_epsilon.pt
Epoch 58, Loss: 0.07912207655380095 / MAE: 0.02446576204604197 / RMSE: 0.035747488894505346
Validation Loss: 0.08221206588102621 / MAE: 0.02538638899688004 / RMSE: 0.03775294191518245
Epoch 59, Loss: 0.08077768047676612 / MAE: 0.024977312146057445 / RMSE: 0.0363424874352051
Validation Loss: 0.0812202539120251 / MAE: 0.02490089860402128 / RMSE: 0.03664740582151897
Epoch 60, Loss: 0.0791627925572886 / MAE: 0.02446285765049539 / RMSE: 0.035708166156606824
Validation Loss: 0.07950489981955386 / MAE: 0.024552873762755802 / RMSE: 0.03613109550634876
Save model to ./models/wo_epsilon.pt
Epoch 61, Loss: 0.07884744619542867 / MAE: 0.024441831581645007 / RMSE: 0.035697365256140735
Validation Loss: 0.07977413966539476 / MAE: 0.024722126265227927 / RMSE: 0.036480667738008586
Epoch 62, Loss: 0.07923328047713148 / MAE: 0.024495894988510923 / RMSE: 0.03573642584980937
Validation Loss: 0.08138618834238621 / MAE: 0.024851806321571027 / RMSE: 0.036616009091838236
Epoch 63, Loss: 0.07907111676771479 / MAE: 0.02442899848014824 / RMSE: 0.03567749793829419
Validation Loss: 0.08065428783319242 / MAE: 0.02492015348835298 / RMSE: 0.03667783136133522
Epoch 64, Loss: 0.07873882521021376 / MAE: 0.024375994613374273 / RMSE: 0.035629026110322475
Validation Loss: 0.0796270839489765 / MAE: 0.02466468848613356 / RMSE: 0.03611777536113442
Epoch 65, Loss: 0.07852346732743358 / MAE: 0.024360380290563862 / RMSE: 0.035543871502554364
Validation Loss: 0.0789076377270367 / MAE: 0.02435544287746204 / RMSE: 0.035934660564284925
Save model to ./models/wo_epsilon.pt
Epoch 66, Loss: 0.07773765740708959 / MAE: 0.024040236826816858 / RMSE: 0.035215266545472676
Validation Loss: 0.0791102915714794 / MAE: 0.024421612418431424 / RMSE: 0.03623377841032309
Epoch 67, Loss: 0.07791795951545827 / MAE: 0.024141577646320186 / RMSE: 0.03534179796952859
Validation Loss: 0.07869835100370709 / MAE: 0.024304534466865948 / RMSE: 0.036054866337947036
Save model to ./models/wo_epsilon.pt
Epoch 68, Loss: 0.07732367238019192 / MAE: 0.023927141772113723 / RMSE: 0.03507795305066781
Validation Loss: 0.07790741085871163 / MAE: 0.024072091771351264 / RMSE: 0.035559882733355974
Save model to ./models/wo_epsilon.pt
Epoch 69, Loss: 0.07762241268135728 / MAE: 0.02403177542940031 / RMSE: 0.03519519142505286
Validation Loss: 0.07837973103578175 / MAE: 0.024223573159597448 / RMSE: 0.035754811450762106
Epoch 70, Loss: 0.07787334946140849 / MAE: 0.024077496917571387 / RMSE: 0.03524865619327787
Validation Loss: 0.07888600052476069 / MAE: 0.024407940256260547 / RMSE: 0.036118278396877174
Epoch 71, Loss: 0.07770801290411596 / MAE: 0.024002484896289315 / RMSE: 0.03515537481065211
Validation Loss: 0.07833974346912147 / MAE: 0.024195915601044612 / RMSE: 0.03569939034453503
Epoch 72, Loss: 0.07868158792876873 / MAE: 0.02422159595116742 / RMSE: 0.03544009725763282
Validation Loss: 0.07925886121882803 / MAE: 0.02428372670874071 / RMSE: 0.036026973830879265
Epoch 73, Loss: 0.07727322807873792 / MAE: 0.023871428662705904 / RMSE: 0.035026664155316974
Validation Loss: 0.07730599685888649 / MAE: 0.02378459666599763 / RMSE: 0.035307192616294225
Save model to ./models/wo_epsilon.pt
Epoch 74, Loss: 0.07726556623654446 / MAE: 0.023874063725203606 / RMSE: 0.03506713478364366
Validation Loss: 0.078200080430142 / MAE: 0.024034454113043304 / RMSE: 0.03572156002141274
Epoch 75, Loss: 0.07688504780304146 / MAE: 0.023715301467767274 / RMSE: 0.03482398998685902
Validation Loss: 0.0775159258809299 / MAE: 0.023940115983011545 / RMSE: 0.03543018532876321
Epoch 76, Loss: 0.07678561539959049 / MAE: 0.023717056494406395 / RMSE: 0.034864241829513344
Validation Loss: 0.07798089298889606 / MAE: 0.02396877696601252 / RMSE: 0.03581308668977573
Epoch 77, Loss: 0.07798929105690344 / MAE: 0.024173028677432776 / RMSE: 0.035468052698198194
Validation Loss: 0.07922859100887444 / MAE: 0.02446269740331061 / RMSE: 0.036174838452926655
Epoch 78, Loss: 0.07678321202318884 / MAE: 0.023686549887203028 / RMSE: 0.0348042680506999
Validation Loss: 0.07772633105885766 / MAE: 0.02387909537305995 / RMSE: 0.035455151675794896
Epoch 79, Loss: 0.07632019598765581 / MAE: 0.023569035089583808 / RMSE: 0.0346569156996447
Validation Loss: 0.07658416880641127 / MAE: 0.023534750210806695 / RMSE: 0.03506816854488349
Save model to ./models/wo_epsilon.pt
Epoch 80, Loss: 0.07571928720208347 / MAE: 0.023351284505833625 / RMSE: 0.03438394901294179
Validation Loss: 0.07684768846349126 / MAE: 0.023643018771606666 / RMSE: 0.03518244817354885
Epoch 81, Loss: 0.07571226820425461 / MAE: 0.023378782364855057 / RMSE: 0.03441760554218834
Validation Loss: 0.0765282664036139 / MAE: 0.02351725808109386 / RMSE: 0.035068385429940355
Save model to ./models/wo_epsilon.pt
Epoch 82, Loss: 0.07612189399787399 / MAE: 0.023494101455009863 / RMSE: 0.03454843454861772
Validation Loss: 0.07739884371342123 / MAE: 0.02388652185169772 / RMSE: 0.03540738993792691
Epoch 83, Loss: 0.07571563950667587 / MAE: 0.023363708483175025 / RMSE: 0.034398807052725924
Validation Loss: 0.07684664813267798 / MAE: 0.023585724571014502 / RMSE: 0.03544938064393456
Epoch 84, Loss: 0.07740671694881077 / MAE: 0.023680308995522342 / RMSE: 0.03477288923067076
Validation Loss: 0.0780382301478103 / MAE: 0.024031301861507752 / RMSE: 0.03546061718524284
Epoch 85, Loss: 0.07639789797398545 / MAE: 0.02349791484107064 / RMSE: 0.03457895557168338
Validation Loss: 0.07689714950213043 / MAE: 0.023497407641153763 / RMSE: 0.03507820238583526
Save model to ./models/wo_epsilon.pt
Epoch 86, Loss: 0.07552332512871389 / MAE: 0.023232378242906596 / RMSE: 0.03427323487208093
Validation Loss: 0.07672464606125504 / MAE: 0.023580425172720746 / RMSE: 0.03512900741028661
Epoch 87, Loss: 0.0760858201831357 / MAE: 0.023489013614313853 / RMSE: 0.034575456696225096
Validation Loss: 0.07618445125182996 / MAE: 0.023382159005489 / RMSE: 0.03495214447136447
Save model to ./models/wo_epsilon.pt
Epoch 88, Loss: 0.07568683535972676 / MAE: 0.02331870050286524 / RMSE: 0.03437112292327874
Validation Loss: 0.07658871454812377 / MAE: 0.02350583208882083 / RMSE: 0.034981508985724816
Epoch 89, Loss: 0.07516898593567599 / MAE: 0.02316280220970653 / RMSE: 0.034133967656258084
Validation Loss: 0.0758534859972518 / MAE: 0.023283819653057355 / RMSE: 0.034784033158651306
Save model to ./models/wo_epsilon.pt
Epoch 90, Loss: 0.07546815974276791 / MAE: 0.02328719133646344 / RMSE: 0.03428689814049514
Validation Loss: 0.07598213726104035 / MAE: 0.02333562225802352 / RMSE: 0.03485499098143645
Epoch 91, Loss: 0.07496042141052035 / MAE: 0.02313777606017494 / RMSE: 0.03410310495010936
Validation Loss: 0.07684202828853257 / MAE: 0.02363655774106964 / RMSE: 0.035274780033139955
Epoch 92, Loss: 0.07569093218075934 / MAE: 0.0232029970083885 / RMSE: 0.03424867278877303
Validation Loss: 0.07630107896621736 / MAE: 0.023396696646477755 / RMSE: 0.03495388802566493
Epoch 93, Loss: 0.07487776855503163 / MAE: 0.023092947406191167 / RMSE: 0.03407459217073921
Validation Loss: 0.07539952982732581 / MAE: 0.023175782837333694 / RMSE: 0.034659501872708706
Save model to ./models/wo_epsilon.pt
Epoch 94, Loss: 0.07464013025865972 / MAE: 0.022974768832109485 / RMSE: 0.0339633133383397
Validation Loss: 0.07519124115571449 / MAE: 0.02308114471853643 / RMSE: 0.03455709046524235
Save model to ./models/wo_epsilon.pt
Epoch 95, Loss: 0.07479358896535614 / MAE: 0.023022958120282395 / RMSE: 0.03401719659150614
Validation Loss: 0.07568881991493229 / MAE: 0.02321923138265431 / RMSE: 0.034821821253304394
Epoch 96, Loss: 0.07484746232247247 / MAE: 0.02303036166558681 / RMSE: 0.03400632675194933
Validation Loss: 0.0757467482106473 / MAE: 0.023207510880731034 / RMSE: 0.034651276287806884
Epoch 97, Loss: 0.07503136917490559 / MAE: 0.023122660320742068 / RMSE: 0.034081717111720845
Validation Loss: 0.07645011973951148 / MAE: 0.023657461449276128 / RMSE: 0.03520609575382119
Epoch 98, Loss: 0.0745751524975659 / MAE: 0.02296975635028412 / RMSE: 0.03393442812183684
Validation Loss: 0.07648068044930725 / MAE: 0.023600549514304753 / RMSE: 0.03499192889414175
Epoch 99, Loss: 0.0744150042332619 / MAE: 0.022885699525152514 / RMSE: 0.03386454861141364
Validation Loss: 0.0755023674158648 / MAE: 0.023202747622624902 / RMSE: 0.03474710353626059
